# -*- coding: utf-8 -*-
"""Laptop Price Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S2g6soOFkb0edFDhHFraTVMqYe4IiC-r

# Projek Pertama Predictive Analytics
## Machine Learning Kelas Mahir


---
##### Nama: Rangga Wibisana Putra Pamungkas
---
Projek pertama dari Machine Learning Kelas Mahir ini adalah membuat Model Predictive Analytics.

# Loading Dataset
"""

# Menghubungkan Drive dengan Colab
from google.colab import drive
drive.mount('/content/drive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/drive/MyDrive/Kaggle"
os.chdir('/content/drive/MyDrive/Kaggle')
!kaggle datasets download -d mrsimple07/laptoppriceprediction

os.chdir('/content')
!mkdir laptop
!unzip -qq /content/drive/MyDrive/Kaggle/laptoppriceprediction.zip  -d laptop
!ls laptop

# Load dataset sebagai dataframe
import pandas as pd
df = pd.read_csv('/content/laptop/Laptop_price.csv')

# Melihat sampel teratas dataframe
df.head()

"""# Exploratory Data Analysis
### 1. Deskripsi Variabel
"""

df.info()

df.describe()

"""### 2. Missing Value dan Outliers"""

df.isnull().sum()

import seaborn as sns
sns.boxplot(x=df['Processor_Speed'])

sns.boxplot(x=df['Screen_Size'])

sns.boxplot(x=df['Weight'])

"""### 3. Univariate Analysis"""

numerical_features = ['Processor_Speed', 'RAM_Size', 'Storage_Capacity', 'Screen_Size', 'Weight', 'Price']
categorical_features = ['Brand']

feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
cat_df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(cat_df)
count.plot(kind='bar', title=feature);

import matplotlib.pyplot as plt
df.hist(bins=50, figsize=(20,15))
plt.show()

"""### 4. Multivariate Analysis"""

for col in categorical_features:
  sns.catplot(x=col, y="Price", kind="bar", dodge=False, height=4, aspect=3, data=df, palette="Set3", hue="Brand")
  plt.title("Average 'Price' Relative to {}".format(col))
  plt.show()

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""# Data Preparation"""

from sklearn.preprocessing import  OneHotEncoder
df = pd.concat([df, pd.get_dummies(df['Brand'], prefix='Brand')],axis=1)
df.drop(['Brand'], axis=1, inplace=True)
df.head()

from sklearn.model_selection import train_test_split

X = df.drop(["Price"], axis =1)
y = df["Price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

from sklearn.preprocessing import StandardScaler

numerical_features = ['Processor_Speed', 'Screen_Size', 'Weight']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""# Model Development"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.linear_model import LinearRegression

knr = KNeighborsRegressor(n_neighbors=10)
rf = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
adb = AdaBoostRegressor(learning_rate=0.05, random_state=55)
lr = LinearRegression()

models = [knr, rf, adb, lr]

# CrossVal Evaluations
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
mae = []
mse = []
r2 = []

crossval = KFold(n_splits=5, shuffle=True, random_state=42)

for model in models:

    # MAE
    model_cv_mae = cross_val_score(
        model,
        X_train,
        y_train,
        cv=crossval,
        scoring='neg_mean_absolute_error',
        error_score='raise'
        )
    mae.append(abs(model_cv_mae.mean()))

    # MSE
    model_cv_mse = cross_val_score(
        model,
        X_train,
        y_train,
        cv=crossval,
        scoring='neg_mean_squared_error',
        error_score='raise'
        )
    mse.append(abs(model_cv_mse.mean()))

    # R2
    model_cv_r2 = cross_val_score(
        model,
        X_train,
        y_train,
        cv=crossval,
        scoring='r2',
        error_score='raise'
        )
    r2.append(model_cv_r2.mean())

"""# Model Evaluation"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

df_eval = pd.DataFrame({
    'Model': ['KNeighbors Regressor', 'RandomForest Regressor',  'AdaBoost Regression', 'Linear Regression'],
    'MAE': mae,
    'MSE': mse,
    'R2':r2
})
df_eval.sort_values(by="MSE", ascending=True)

# Compare Best 2
score_mae = []
score_mse = []
score_r2 = []

for model in [lr, rf]:

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    score_mae.append(mean_absolute_error(y_test, y_pred))
    score_mse.append(mean_squared_error(y_test, y_pred))
    score_r2.append(r2_score(y_test, y_pred))

test_eval = pd.DataFrame({'MAE': score_mae,'MSE': score_mse,'R2': score_r2},
                         index=['Linear Regressor','GradientBoosting Regressor'])
test_eval

# Test On Seen
y_pred = lr.predict(X_test)

m_lr = pd.DataFrame({
    'y_test' : y_test,
    'y_pred' : y_pred
})

m_lr['Residual'] = y_pred - y_test
m_lr.sort_values(by="Residual", ascending=False)

plt.figure(figsize=(16, 10))

plt.subplot(221)
sns.regplot(x=y_test, y=y_pred,color="red").set(title='Actual vs. Prediction Price', xlabel='Actual Price', ylabel='Predicted Price')
plt.subplot(222)
sns.histplot(m_lr['Residual']).set(title='Residual Distribution Plot')

# Get coefficients (feature importances)
coefficients = lr.coef_

feature_imp = pd.Series(coefficients, index=X.columns).sort_values(ascending=True)
feature_imp.plot(kind='barh', title='Feature Importances')
plt.show()